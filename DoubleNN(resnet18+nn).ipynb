{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2A0I7AEW_dij",
        "outputId": "52eece93-8a83-4159-9487-f0c3e9d11c45"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "当前工作路径： /content/drive/MyDrive/Cornell/pvz\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from google.colab import drive\n",
        "#drive.mount('/content/drive/')\n",
        "import os\n",
        "project_path = '/content/drive/MyDrive/Cornell/pvz'\n",
        "os.chdir(project_path)\n",
        "print(\"当前工作路径：\", os.getcwd())\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from PIL import Image\n",
        "from torch.utils.data import Dataset, DataLoader, random_split, Subset\n",
        "from torchvision import transforms, models\n",
        "import torchvision.transforms.functional as TF\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "import os\n",
        "import time\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "# torch.manual_seed(42)\n",
        "# np.random.seed(42)\n",
        "# if torch.cuda.is_available():\n",
        "#     torch.cuda.manual_seed_all(42)"
      ],
      "metadata": {
        "id": "D3betHL9QwQo"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Configuration"
      ],
      "metadata": {
        "id": "mP_RUlg5RBAq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Data paths\n",
        "TRAIN_PKL_PATH = 'train.pkl'\n",
        "TEST_PKL_PATH = 'test.pkl'\n",
        "MODEL_SAVE_PATH = 'best_siamese_resnet_acc.pth'\n",
        "SUBMISSION_CSV_PATH = 'submission_siamese_resnet_acc.csv'\n",
        "\n",
        "# Hyperparameters\n",
        "BATCH_SIZE = 64\n",
        "LEARNING_RATE = 1e-4 # Adjusted based on previous suggestion\n",
        "WEIGHT_DECAY = 1e-4 # Adjusted based on previous suggestion\n",
        "EPOCHS = 80 # Max epochs\n",
        "PATIENCE_LR = 5\n",
        "PATIENCE_ES = 10 # Early stopping patience\n",
        "VALIDATION_SPLIT = 0.2 # Use 20% for validation\n",
        "USE_PRETRAINED_BASE = True # Use ImageNet weights for base ResNet?\n",
        "\n",
        "# Inference Configuration\n",
        "INFERENCE_BATCH_SIZE = 128 # Can be larger for inference\n",
        "\n",
        "# Device\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {DEVICE}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "dLB8iy62_gBc",
        "outputId": "27dffa65-98ba-46de-98cb-93e4e8bce20f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Handling"
      ],
      "metadata": {
        "id": "BeQ-Rj20Rhr0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Augmentation Definition (for Training)\n",
        "augment_transform = transforms.Compose([\n",
        "    transforms.RandomRotation(10),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomCrop(24, padding=2), # Consider if this crop is too aggressive\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,)) # Normalize single channel\n",
        "])\n",
        "\n",
        "# Dataset\n",
        "class RPSSiameseDataset(Dataset):\n",
        "    def __init__(self, pkl_path, transform=None):\n",
        "        self.imgs1 = None\n",
        "        self.imgs2 = None\n",
        "        self.labels = None\n",
        "        self.transform = transform\n",
        "\n",
        "        try:\n",
        "            with open(pkl_path, 'rb') as f:\n",
        "                data = pickle.load(f)\n",
        "            print(f\"Pickle file '{pkl_path}' loaded successfully.\")\n",
        "\n",
        "            print(\"Attempting to stack 'img1' data...\")\n",
        "            self.imgs1 = np.stack(data['img1']).astype(np.uint8) # Stack and ensure uint8 for PIL\n",
        "            print(f\"  'img1' stacked successfully. Shape: {self.imgs1.shape}\")\n",
        "\n",
        "            print(\"Attempting to stack 'img2' data...\")\n",
        "            self.imgs2 = np.stack(data['img2']).astype(np.uint8) # Stack and ensure uint8 for PIL\n",
        "            print(f\"  'img2' stacked successfully. Shape: {self.imgs2.shape}\")\n",
        "\n",
        "            labels_raw = np.array(data['label'])\n",
        "            self.labels = torch.tensor((labels_raw == 1).astype(np.int64)) # 1 if img1 beats img2, else 0\n",
        "\n",
        "            assert len(self.imgs1) == len(self.labels), \"Mismatch between img1 count and labels count.\"\n",
        "            assert len(self.imgs2) == len(self.labels), \"Mismatch between img2 count and labels count.\"\n",
        "            assert self.imgs1.shape[1:] == (24, 24), f\"img1 shape error: {self.imgs1.shape}\"\n",
        "            assert self.imgs2.shape[1:] == (24, 24), f\"img2 shape error: {self.imgs2.shape}\"\n",
        "\n",
        "            print(f\"Dataset initialized successfully from {pkl_path}: {len(self.labels)} samples.\")\n",
        "\n",
        "        except FileNotFoundError:\n",
        "            print(f\"Error: File not found at {pkl_path}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error during dataset initialization from {pkl_path}: {e}\")\n",
        "\n",
        "            self.imgs1, self.imgs2, self.labels = None, None, None\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels) if self.labels is not None else 0\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if self.imgs1 is None or self.imgs2 is None:\n",
        "             raise IndexError(\"Dataset not initialized correctly.\")\n",
        "\n",
        "        im1_pil = Image.fromarray(self.imgs1[idx]) # Already uint8 from __init__\n",
        "        im2_pil = Image.fromarray(self.imgs2[idx]) # Already uint8 from __init__\n",
        "        y = self.labels[idx]\n",
        "\n",
        "        # Apply independent transforms\n",
        "        if self.transform:\n",
        "            im1 = self.transform(im1_pil)\n",
        "            im2 = self.transform(im2_pil)\n",
        "        else:\n",
        "            to_tensor = transforms.ToTensor()\n",
        "            im1 = to_tensor(im1_pil)\n",
        "            im2 = to_tensor(im2_pil)\n",
        "\n",
        "        return im1, im2, y\n",
        "\n",
        "# Dataset for Inference (Corrected Loading)\n",
        "class RPSInferenceDataset(Dataset):\n",
        "    def __init__(self, pkl_path, ids_key='id', img1_key='img1', img2_key='img2'):\n",
        "        self.ids = None\n",
        "        self.imgs1 = None\n",
        "        self.imgs2 = None\n",
        "        self.transform = transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize((0.5,), (0.5,))\n",
        "        ])\n",
        "\n",
        "        try:\n",
        "            with open(pkl_path, 'rb') as f:\n",
        "                 data = pickle.load(f)\n",
        "            print(f\"Pickle file '{pkl_path}' loaded successfully for inference.\")\n",
        "\n",
        "            self.ids = data.get(ids_key)\n",
        "            if self.ids is None:\n",
        "                 raise ValueError(f\"Key '{ids_key}' not found in pickle file.\")\n",
        "            self.ids = np.array(self.ids) # Ensure IDs are numpy array\n",
        "\n",
        "\n",
        "            print(\"Attempting to stack 'img1' data for inference...\")\n",
        "            img1_data = data.get(img1_key)\n",
        "            if img1_data is None: raise ValueError(f\"Key '{img1_key}' not found.\")\n",
        "            self.imgs1 = np.stack(img1_data).astype(np.uint8)\n",
        "            print(f\"  'img1' stacked successfully. Shape: {self.imgs1.shape}\")\n",
        "\n",
        "\n",
        "            print(\"Attempting to stack 'img2' data for inference...\")\n",
        "            img2_data = data.get(img2_key)\n",
        "            if img2_data is None: raise ValueError(f\"Key '{img2_key}' not found.\")\n",
        "            self.imgs2 = np.stack(img2_data).astype(np.uint8)\n",
        "            print(f\"  'img2' stacked successfully. Shape: {self.imgs2.shape}\")\n",
        "\n",
        "            # Validation checks\n",
        "            assert len(self.imgs1) == len(self.ids), \"Mismatch between img1 count and ID count.\"\n",
        "            assert len(self.imgs2) == len(self.ids), \"Mismatch between img2 count and ID count.\"\n",
        "            assert self.imgs1.shape[1:] == (24, 24), f\"img1 shape error: {self.imgs1.shape}\"\n",
        "            assert self.imgs2.shape[1:] == (24, 24), f\"img2 shape error: {self.imgs2.shape}\"\n",
        "\n",
        "            print(f\"Inference dataset initialized successfully from {pkl_path}: {len(self.ids)} samples.\")\n",
        "\n",
        "\n",
        "        except FileNotFoundError:\n",
        "            print(f\"Error: File not found at {pkl_path}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error during inference dataset initialization from {pkl_path}: {e}\")\n",
        "            self.ids, self.imgs1, self.imgs2 = None, None, None\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.ids) if self.ids is not None else 0\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if self.imgs1 is None or self.imgs2 is None or self.ids is None:\n",
        "             raise IndexError(\"Inference dataset not initialized correctly.\")\n",
        "\n",
        "        im1_pil = Image.fromarray(self.imgs1[idx])\n",
        "        im2_pil = Image.fromarray(self.imgs2[idx])\n",
        "        current_id = self.ids[idx]\n",
        "\n",
        "        # Apply only ToTensor and Normalize\n",
        "        im1 = self.transform(im1_pil)\n",
        "        im2 = self.transform(im2_pil)\n",
        "\n",
        "        return im1, im2, current_id\n",
        "\n",
        "print(\"Corrected Dataset classes defined.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rtmjhKncRWJw",
        "outputId": "5b6a59a2-27b9-4f3d-e21c-06efdcfbf776"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Corrected Dataset classes defined.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Definition"
      ],
      "metadata": {
        "id": "AMMeI6XtSBEe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Base Network (resnet18 for Feature Extractor)\n",
        "def get_base_resnet18(pretrained=True):\n",
        "    weights = models.ResNet18_Weights.DEFAULT if pretrained else None\n",
        "    backbone = models.resnet18(weights=weights)\n",
        "    original_conv1 = backbone.conv1\n",
        "    backbone.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "\n",
        "    if pretrained and original_conv1.weight.shape[1] == 3:\n",
        "        new_weights = original_conv1.weight.data.mean(dim=1, keepdim=True)\n",
        "        backbone.conv1.weight.data = new_weights\n",
        "        # print(\"Adapted pretrained weights for conv1 (1 channel input).\") # Optional print\n",
        "\n",
        "    num_ftrs = backbone.fc.in_features\n",
        "    backbone.fc = nn.Identity() # Remove final classification layer\n",
        "\n",
        "    return backbone, num_ftrs\n",
        "\n",
        "# Siamese Network\n",
        "class SiameseNet(nn.Module):\n",
        "    def __init__(self, pretrained_base=True):\n",
        "        super().__init__()\n",
        "        self.base_network, num_base_ftrs = get_base_resnet18(pretrained=pretrained_base)\n",
        "        self.classifier_head = nn.Sequential(\n",
        "            nn.Linear(num_base_ftrs * 2, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm1d(256),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(256, 2) # 2 classes for CrossEntropyLoss (0 or 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, input1, input2):\n",
        "        feat1 = self.base_network(input1)\n",
        "        feat2 = self.base_network(input2)\n",
        "        combined_features = torch.cat((feat1, feat2), dim=1)\n",
        "        output = self.classifier_head(combined_features)\n",
        "        return output\n",
        "\n",
        "print(\"Model classes defined.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YDm8KmfFR_Bk",
        "outputId": "d4756991-1adb-4bea-8769-af0d23480f73"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model classes defined.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "75ZwDbfhSUdm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_one_epoch(model, loader, criterion, optimizer, device):\n",
        "    model.train() # Set model to training mode\n",
        "    total_loss = correct = total = 0\n",
        "    start_time = time.time()\n",
        "    for batch_idx, (im1, im2, y) in enumerate(loader):\n",
        "        im1, im2, y = im1.to(device), im2.to(device), y.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        logits = model(im1, im2)\n",
        "        loss = criterion(logits, y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item() * im1.size(0)\n",
        "        preds = logits.argmax(dim=1)\n",
        "        correct += (preds == y).sum().item()\n",
        "        total += y.size(0)\n",
        "\n",
        "        # Optional: Print progress within epoch\n",
        "        # if batch_idx % 50 == 0:\n",
        "        #     print(f\"  Batch {batch_idx}/{len(loader)}, Loss: {loss.item():.4f}\")\n",
        "\n",
        "    epoch_time = time.time() - start_time\n",
        "    avg_loss = total_loss / total if total > 0 else 0\n",
        "    avg_acc = correct / total if total > 0 else 0\n",
        "    print(f\"  Train Time: {epoch_time:.2f}s\")\n",
        "    return avg_loss, avg_acc\n",
        "\n",
        "def validate(model, loader, criterion, device):\n",
        "    model.eval() # Set model to evaluation mode\n",
        "    total_loss = correct = total = 0\n",
        "    with torch.no_grad(): # Disable gradient calculation\n",
        "        for im1, im2, y in loader:\n",
        "            im1, im2, y = im1.to(device), im2.to(device), y.to(device)\n",
        "            logits = model(im1, im2)\n",
        "            loss = criterion(logits, y)\n",
        "            total_loss += loss.item() * im1.size(0)\n",
        "            preds = logits.argmax(dim=1)\n",
        "            correct += (preds == y).sum().item()\n",
        "            total += y.size(0)\n",
        "\n",
        "    avg_loss = total_loss / total if total > 0 else 0\n",
        "    avg_acc = correct / total if total > 0 else 0\n",
        "    return avg_loss, avg_acc\n",
        "\n",
        "print(\"Training/validation functions defined.\")\n",
        "\n",
        "print(\"\\n Starting Training Phase\")\n",
        "\n",
        "full_dataset = RPSSiameseDataset(TRAIN_PKL_PATH, transform=augment_transform)\n",
        "if len(full_dataset) == 0:\n",
        "    print(\"Training aborted: Could not load training data.\")\n",
        "else:\n",
        "    n_total = len(full_dataset)\n",
        "    n_val = int(n_total * VALIDATION_SPLIT)\n",
        "    n_train = n_total - n_val\n",
        "\n",
        "    if n_val == 0 and n_total > 0: # Ensure validation set is not empty if possible\n",
        "        n_train = max(1, n_total - 1)\n",
        "        n_val = n_total - n_train\n",
        "        print(f\"Warning: Validation split resulted in 0 samples. Using {n_val} sample for validation.\")\n",
        "\n",
        "    print(f\"Splitting data: {n_train} train, {n_val} validation\")\n",
        "    try:\n",
        "        train_dataset, val_dataset = random_split(full_dataset, [n_train, n_val])\n",
        "    except ValueError as e:\n",
        "         print(f\"Error during random_split: {e}. Ensure dataset has samples and split is valid.\")\n",
        "         train_dataset, val_dataset = None, None # Abort training if split fails\n",
        "\n",
        "    if train_dataset and val_dataset:\n",
        "        train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=os.cpu_count()//2, pin_memory=True)\n",
        "        val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=os.cpu_count()//2, pin_memory=True)\n",
        "        print(f\"DataLoaders created: Train batches={len(train_loader)}, Val batches={len(val_loader)}\")\n",
        "\n",
        "        # Initialize Model, Loss, Optimizer, Scheduler\n",
        "        model = SiameseNet(pretrained_base=USE_PRETRAINED_BASE).to(DEVICE)\n",
        "        print(f\"Model: SiameseNet with {'pretrained' if USE_PRETRAINED_BASE else 'random'} base ResNet-18 loaded to {DEVICE}.\")\n",
        "\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "        optimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
        "        scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
        "            optimizer, mode='max', factor=0.5, patience=PATIENCE_LR, verbose=True\n",
        "        )\n",
        "\n",
        "        # Training Loop\n",
        "        best_val_acc = 0.0\n",
        "        epochs_no_improve = 0\n",
        "        training_start_time = time.time()\n",
        "\n",
        "        for epoch in range(1, EPOCHS + 1):\n",
        "            print(f\"\\nEpoch {epoch}/{EPOCHS}\")\n",
        "            tr_loss, tr_acc = train_one_epoch(model, train_loader, criterion, optimizer, DEVICE)\n",
        "\n",
        "            # Validation\n",
        "            if len(val_loader) > 0:\n",
        "                va_loss, va_acc = validate(model, val_loader, criterion, DEVICE)\n",
        "                current_lr = optimizer.param_groups[0]['lr']\n",
        "                print(f\"  Epoch {epoch:2d} Summary | Train Loss: {tr_loss:.4f}, Acc: {tr_acc:.4f} | Val Loss: {va_loss:.4f}, Acc: {va_acc:.4f} | LR: {current_lr:.1e}\")\n",
        "\n",
        "                scheduler.step(va_acc) # Scheduler steps based on validation accuracy\n",
        "\n",
        "                if va_acc > best_val_acc:\n",
        "                    print(f\"  🚀 Validation accuracy improved from {best_val_acc:.4f} to {va_acc:.4f}. Saving model...\")\n",
        "                    best_val_acc = va_acc\n",
        "                    torch.save(model.state_dict(), MODEL_SAVE_PATH)\n",
        "                    epochs_no_improve = 0\n",
        "                else:\n",
        "                    epochs_no_improve += 1\n",
        "                    print(f\"  ⏳ Validation accuracy did not improve for {epochs_no_improve}/{PATIENCE_ES} epochs.\")\n",
        "                    if epochs_no_improve >= PATIENCE_ES:\n",
        "                        print(f\"  🚨 Early stopping triggered after epoch {epoch}. Best validation accuracy: {best_val_acc:.4f}\")\n",
        "                        break\n",
        "            else:\n",
        "                print(f\"  Epoch {epoch:2d} Summary | Train Loss: {tr_loss:.4f}, Acc: {tr_acc:.4f} | (No validation set)\")\n",
        "                # torch.save(model.state_dict(), f\"model_epoch_{epoch}.pth\")\n",
        "\n",
        "        training_duration = time.time() - training_start_time\n",
        "        print(f\"\\n--- Training Finished ---\")\n",
        "        print(f\"Total Training Time: {training_duration:.2f}s\")\n",
        "        print(f\"Best Validation Accuracy: {best_val_acc:.4f}\")\n",
        "        print(f\"Best model saved to: {MODEL_SAVE_PATH}\")\n",
        "\n",
        "\n",
        "print(\"\\n--- Starting Evaluation Phase (on Validation Set) ---\")\n",
        "\n",
        "# Load Best Model\n",
        "if os.path.exists(MODEL_SAVE_PATH):\n",
        "    eval_model = SiameseNet(pretrained_base=USE_PRETRAINED_BASE).to(DEVICE) # Re-create model structure\n",
        "    try:\n",
        "        eval_model.load_state_dict(torch.load(MODEL_SAVE_PATH, map_location=DEVICE))\n",
        "        eval_model.eval() # Set to evaluation mode\n",
        "        print(f\"Loaded best model state from {MODEL_SAVE_PATH}\")\n",
        "\n",
        "        # Evaluate on the Validation Set (using no augmentation)\n",
        "        if 'val_dataset' in locals() and val_dataset is not None and len(val_dataset) > 0:\n",
        "             # Create a loader for validation set *without* augmentation for consistent eval\n",
        "             val_eval_loader = DataLoader(val_dataset, batch_size=INFERENCE_BATCH_SIZE, shuffle=False, num_workers=os.cpu_count()//2, pin_memory=True)\n",
        "\n",
        "             # Need criterion for the validate function, even if just for loss calculation\n",
        "             eval_criterion = nn.CrossEntropyLoss()\n",
        "             val_eval_loss, val_eval_acc = validate(eval_model, val_eval_loader, eval_criterion, DEVICE)\n",
        "             print(f\"Evaluation Accuracy on Validation Set (Best Model): {val_eval_acc:.4f}\")\n",
        "             print(f\"Evaluation Loss on Validation Set (Best Model):   {val_eval_loss:.4f}\")\n",
        "        else:\n",
        "             print(\"Skipping evaluation on validation set (validation set not available or empty).\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading or evaluating model: {e}\")\n",
        "else:\n",
        "    print(f\"Skipping evaluation: Model file not found at {MODEL_SAVE_PATH}\")\n"
      ],
      "metadata": {
        "id": "PCJeauvYSU3u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inference"
      ],
      "metadata": {
        "id": "IeOPzHrDS-og"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n Starting Inference Phase\")\n",
        "\n",
        "# Load Best Model (if not already loaded for evaluation)\n",
        "if 'eval_model' not in locals() or eval_model is None:\n",
        "    if os.path.exists(MODEL_SAVE_PATH):\n",
        "        model_for_inference = SiameseNet(pretrained_base=USE_PRETRAINED_BASE).to(DEVICE)\n",
        "        try:\n",
        "            model_for_inference.load_state_dict(torch.load(MODEL_SAVE_PATH, map_location=DEVICE))\n",
        "            print(f\"Loaded best model state from {MODEL_SAVE_PATH} for inference.\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading model for inference: {e}\")\n",
        "            model_for_inference = None\n",
        "    else:\n",
        "        print(f\"Cannot perform inference: Model file not found at {MODEL_SAVE_PATH}\")\n",
        "        model_for_inference = None\n",
        "else:\n",
        "     model_for_inference = eval_model # Reuse model loaded during evaluation\n",
        "     print(\"Using model already loaded during evaluation phase.\")\n",
        "\n",
        "#  Load Test Data\n",
        "if model_for_inference:\n",
        "    model_for_inference.eval() # Ensure model is in eval mode\n",
        "\n",
        "    test_dataset = RPSInferenceDataset(TEST_PKL_PATH)\n",
        "    if len(test_dataset) > 0:\n",
        "        test_loader = DataLoader(test_dataset, batch_size=INFERENCE_BATCH_SIZE, shuffle=False, num_workers=os.cpu_count()//2)\n",
        "        print(f\"Test DataLoader created: {len(test_loader)} batches.\")\n",
        "\n",
        "        #  Perform Inference\n",
        "        all_preds = []\n",
        "        all_ids = []\n",
        "        inference_start_time = time.time()\n",
        "        with torch.no_grad():\n",
        "            for im1, im2, ids_batch in test_loader:\n",
        "                im1, im2 = im1.to(DEVICE), im2.to(DEVICE)\n",
        "                logits = model_for_inference(im1, im2)\n",
        "                preds = logits.argmax(dim=1).cpu().numpy()\n",
        "                all_preds.append(preds)\n",
        "                all_ids.extend(ids_batch.numpy() if isinstance(ids_batch, torch.Tensor) else ids_batch) # Handle ids if they are tensors or lists\n",
        "\n",
        "        inference_duration = time.time() - inference_start_time\n",
        "        print(f\"Inference completed in {inference_duration:.2f}s\")\n",
        "\n",
        "        if all_preds:\n",
        "             final_preds = np.concatenate(all_preds)\n",
        "        else:\n",
        "             final_preds = np.array([])\n",
        "             print(\"Warning: No predictions were generated.\")\n",
        "\n",
        "        # Post-processing & Submission\n",
        "        print(\"\\n--- Starting Post-processing & Submission ---\")\n",
        "\n",
        "        if len(final_preds) == len(all_ids):\n",
        "            # Map predictions (0/1) back to labels (-1/+1)\n",
        "            final_labels = np.where(final_preds == 1, 1, -1)\n",
        "\n",
        "            # Create submission DataFrame\n",
        "            submission_df = pd.DataFrame({'id': all_ids, 'label': final_labels})\n",
        "\n",
        "            # Save to CSV\n",
        "            try:\n",
        "                submission_df.to_csv(SUBMISSION_CSV_PATH, index=False)\n",
        "                print(f\"✅ Submission file saved successfully to: {SUBMISSION_CSV_PATH}\")\n",
        "                # Display first few rows\n",
        "                print(\"\\nSubmission file preview:\")\n",
        "                print(submission_df.head())\n",
        "            except Exception as e:\n",
        "                print(f\"Error saving submission file: {e}\")\n",
        "        else:\n",
        "            print(f\"Error: Number of predictions ({len(final_preds)}) does not match number of IDs ({len(all_ids)}). Cannot create submission file.\")\n",
        "\n",
        "    else:\n",
        "        print(\"Skipping inference: Test dataset could not be loaded or is empty.\")\n",
        "else:\n",
        "    print(\"Skipping inference: Model not loaded.\")\n",
        "\n",
        "print(\"\\n--- Notebook Execution Finished ---\")"
      ],
      "metadata": {
        "id": "jKssoLbKS_6z"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}